<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Enric Moreu viva presentation</title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/white.css">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
    <div class="reveal">
        <div class="slides">
            <!-- Title -->
            <section>
                <h3>Exploring Synthetic Image Generation for Training Computer Vision Models under Data Scarcity</h3>
                <br>
                <h4>Enric Moreu, B.E., M.E.</h4>
                <br>
                <h5>Supervised by Prof. Noel E. O’Connor and Co-supervised by Dr. Kevin McGuinness</h5>
                <br>
                <h5>August 2023</h5>
            </section>

            <!-- Index -->
            <section>
                <h3>Index</h3>
                <ol>
                    <li>3D-based synthetic data</li>
                    <li>Methodology</li>
                    <li>Domain Randomization</li>
                    <li>Domain Adaptation</li>
                    <li>Pseudo-labels</li>
                    <li>Conclusions</li>
                </ol>
            </section>

            <!-- 3D-based synthetic data -->
            <section>
                <section data-auto-animate>
                    <h2>3D-based synthetic data</h2>
                    <div class="r-hstack">
                        <div>
                            <img src="images/3d_env.png" height="400">
                            <p>3D environment</p>
                        </div>
                    </div>
                    <cite style="position:fixed; bottom: 1%; left: 1%;">Community, B. O. (2018). Blender - a 3D
                        modelling and rendering package. Stichting Blender Foundation, Amsterdam. Retrieved from <a
                            href="http://www.blender.org" target="_blank">http://www.blender.org</a></cite>
                </section>
                <section data-auto-animate>
                    <h2>3D-based synthetic data</h2>
                    <div class="r-hstack">
                        <div>
                            <!-- Adjust width to avoid moving title -->
                            <iframe title="Little Blue Penguin / Kororā" frameborder="0" allowfullscreen
                                mozallowfullscreen="true" webkitallowfullscreen="true"
                                allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking
                                execution-while-out-of-viewport execution-while-not-rendered web-share height="437"
                                src="https://sketchfab.com/models/8a58020139cf43bc821bfdfa01e13208/embed?dnt=1">
                            </iframe>
                            <p>3D model</p>
                        </div>
                    </div>
                    <cite style="position:fixed; bottom: 1%; left: 42%;">Source: <a
                            href="https://sketchfab.com/3d-models/little-blue-penguin-korora-8a58020139cf43bc821bfdfa01e13208"
                            target="_blank">Sketchfab</a></cite>
                </section>
                <section data-auto-animate>
                    <h2>3D-based synthetic data</h2>
                    <div class="r-hstack">
                        <div>
                            <img src="images/background.png" height="400">
                            <p>Background image</p>
                        </div>
                    </div>
                    <cite style="position:fixed; bottom: 1%; left: 1%;">Zhou, B., Lapedriza, A., Khosla, A., Oliva, A.,
                        & Torralba, A. (2017). <a href="http://places2.csail.mit.edu/index.html" target="_blank">Places:
                            A 10 million Image Database for Scene Recognition.</a><em> IEEE Transactions on Pattern
                            Analysis and Machine Intelligence.</em></cite>
                </section>
                <section data-auto-animate>
                    <h2>3D-based synthetic data</h2>
                    <img src="images/people1.png" height="400">
                    <p>Lighting and camera parameters</p>
                </section>

            </section>
            <!-- Methodology -->
            <section>
                <section data-auto-animate>
                    <h2>Methodology</h2>
                    <div style="text-align: left;">
                        <h4><strong>1. Generate </strong>synthetic images</h4>
                        <p class="fragment" data-fragment-index="4">RQ1: How realistic should
                            the synthetic data be?</p>
                        <br>
                        <h4 class="fragment" data-fragment-index="2"><strong>2. Train </strong> a computer vision model
                        </h4>
                        <p class="fragment" data-fragment-index="5">RQ2: Can labels improve the
                            synthetic images?</p>
                        <br>
                        <h4 class="fragment" data-fragment-index="3"><strong>3. Evaluate </strong>on real images</h4>
                        <p class="fragment" data-fragment-index="6">RQ3: How can we use
                            unannotated real images to improve the model? </p>
                    </div>
                </section>
            </section>

            <!-- Domain randomization  -->
            <section data-auto-animate>
                <section data-auto-animate>
                    <p>RQ1: How realistic should
                        the synthetic data be?</p>
                    <div class="r-hstack justify-center">
                        <div>
                            <iframe height="420" width="620" frameborder="0"
                                src="https://viewscreen.githubusercontent.com/view/solid?url=https%3a%2f%2fraw.githubusercontent.com%2fsublimeguile%2fmodel_army%2fmaster%2fwill%20clean.stl"
                                title="will clean.stl"></iframe>
                            85,324 faces
                        </div>
                        <div>
                            <script
                                src="https://embed.github.com/view/3d/enric1994/viva/master/models/lowpoly.stl"></script>
                            102 faces
                        </div>

                    </div>
                </section>

                <section data-auto-animate>
                    <h2 data-id="domain-randomization">Domain Randomization</h2>
                    <small class="fragment">&#9744;Domain Randomization for Object Counting (2021)</small>
                </section>

                <section data-auto-animate data-auto-animate-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)">
                    <p>By default, computer vision models learn to <strong>extrapolate</strong> between domains</p>
                    <div class="r-hstack justify-center">
                        <div data-id="box1"
                            style="border:solid; width: 200px; height: 200px; margin: 10px; border-radius: 400px; justify-content: center;">
                            <div style="margin-top: 35%;">Synthetic
                            </div>
                        </div>
                        <div><span style="font-size: 50px;">&#10230;</span>
                        </div>
                        <div data-id="box2"
                            style="border: solid; width: 200px; height: 200px; margin: 10px; border-radius: 400px;">
                            <div style="margin-top: 35%;">Real
                            </div>
                        </div>
                    </div>
                </section>

                <section data-auto-animate data-auto-animate-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)">
                    <div class="r-stack">
                        <div data-id="box1" style="border: solid; width: 500px; height: 500px; border-radius: 400px;">
                            <div style="margin-top: 10%;">Synthetic
                            </div>
                        </div>
                        <div data-id="box2" style="border: solid; width: 200px; height: 200px; border-radius: 400px;">
                            <div style="margin-top: 35%;">Real
                            </div>
                        </div>
                    </div>
                    <p style="margin-top: 20px;">Domain randomization makes the model <strong>interpolate</strong>
                        to
                        the target domain</p>
                </section>

            </section>
            <section>
                <section><img src="images/people3.png" height="600"></section>
                <section data-auto-animate>
                    <h2>Randomizing a synthetic dataset</h2>
                    <div class="r-hstack">

                        <img src="images/people2.png" width="450" height="300">
                    </div>
                </section>

                <section data-auto-animate>
                    <h2>Randomizing a synthetic dataset</h2>
                    <div class="r-hstack">
                        <img src="images/people2.png" width="450" height="300">
                        <img src="images/dtd.png" width="450" height="300">
                    </div>
                    <cite style="position:fixed; bottom: 1%; left: 1%;">M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, &
                        and A. Vedaldi (2014). <a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/"
                            target="_blank">Describing Textures in the Wild. </a><em>In Proceedings of the IEEE Conf. on
                            Computer Vision and Pattern Recognition (CVPR).</em></cite>
                </section>


                <section data-auto-animate>
                    <div class="r-hstack">
                        <img src="images/people2.png" width="450" height="300">
                        <img src="images/dtd.png" width="550" height="350">
                    </div>
                    <pre><code class="python3" data-trim data-line-numbers="|1,4|2,5">
                        import random
                        from sklearn.datasets import make_blobs

                        light_intensity = random.uniform(0.1, 2)
                        X, _ = make_blobs(n_samples=100, centers=10, n_features=2)
                          </code></pre>
                </section>
            </section>

            <!-- transition to DA  -->
            <section>
                <section>
                    <h4>
                        Domain Randomization doesn't work for domains with low variance
                    </h4>
                    <!-- https://www.ucd-ml-mi.com/ -->
                    <div class="fragment"><img src="images/medical-images.png" height="450">
                        <cite style="position:fixed; bottom: 1%; left: 27%;">Source: <a
                                href="https://www.ucd-ml-mi.com/" target="_blank">Machine Learning in Medical Imaging
                                and Diagnostics (UCD)</a></cite>
                    </div>

                </section>
            </section>

            <!-- Domain adaptation -->
            <section>
                <section>
                    <h2>Domain adaptation</h2>
                    <div class="fragment" style="text-align: left;">
                        <small>&#9744;Synthetic data for unsupervised polyp segmentation (2021)</small>
                        <small>&#9744;Joint one-sided synthetic unpaired image translation and segmentation for
                            colorectal
                            cancer prevention (2022)</small>
                    </div>
                </section>

                <section data-auto-animate data-auto-animate-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)">
                    <div class="r-hstack justify-center">
                        <div data-id="box1"
                            style="border:solid; width: 400px; height: 400px; margin: 10px; border-radius: 400px; justify-content: center;">
                            <div style="margin-top: 45%;">Synthetic
                            </div>
                        </div>
                        <div><span style="font-size: 50px;">&#10230;</span>
                        </div>
                        <div data-id="box2"
                            style="border: solid; width: 400px; height: 400px; margin: 10px; border-radius: 400px;">
                            <div style="margin-top: 45%;">Real
                            </div>
                        </div>
                    </div>
                </section>

                <section data-auto-animate data-auto-animate-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)">
                    <div class="r-hstack">
                        <div data-id="box1" style="border: solid; width: 500px; height: 500px; border-radius: 400px;">
                        </div>
                        <div data-id="box2"
                            style="border: solid; width: 500px; height: 500px; border-radius: 400px; margin-left: -150px;">
                        </div>
                    </div>
                    <p style="margin-top: 20px;">Domain adaptation <strong>reduces the dissimilarity</strong>
                        between
                        domains</p>
                </section>

            </section>

            <!-- Synth-colon -->
            <section>
                <section>
                    <h3>Polyp segmentation</h3>
                    <img src="images/polyp1.png" height="450">
                    <cite style="position:fixed; bottom: 1%; left: 1%;">Pogorelov, K., Randel, K., Griwodz, C.,
                        Eskeland, S., Lange, T., Johansen, D., Spampinato, C., Dang-Nguyen, D.T., Lux, M., Schmidt, P.,
                        Riegler, M., & Halvorsen, P. (2017). <a href="https://datasets.simula.no/kvasir/"
                            target="_blank">KVASIR: A Multi-Class Image Dataset for Computer Aided Gastrointestinal
                            Disease Detection. </a><em>In Proceedings of the 8th ACM on Multimedia Systems Conference
                            (pp. 164–169). ACM.</em></cite>
                </section>

                <section data-auto-animate
                    data-background-iframe="https://enric1994.github.io/viva/images/video-colon.mp4"
                    data-background-size="cover">
                    <h2
                        style="color: black; -webkit-text-fill-color: white; -webkit-text-stroke-width: 2px; -webkit-text-stroke-color: black;">
                        Synth-colon dataset</h2>
                </section>

                <section data-auto-animate>
                    <h2>Synth-colon dataset</h2>
                    <ul>
                        <li>20.000 synthetic images</li>
                        <li>Self-annotated</li>
                        <li>Depth maps</li>
                        <li>3D objects</li>
                    </ul>
                </section>

                <section data-auto-animate>
                    <h2>Synth-colon dataset</h2>
                    <div class="r-hstack">
                        <div>

                            <img src="images/synth-colon.png" height="400">
                        </div>
                        <div>

                            <img src="images/depth.png" height="400">
                        </div>
                        <div style="height: 290px !important;">
                            <script
                                src="https://embed.github.com/view/3d/enric1994/viva/master/models/synth-colon.stl"></script>
                        </div>
                    </div>
                </section>
            </section>

            <!-- Domain adaptation diagrams -->
            <section>
                <section data-auto-animate>
                    <h2>Adapting a synthetic dataset</h2>
                    <img src="images/d1.png" height="300">
                    <cite style="position:fixed; bottom: 1%; left: 1%;">Chien-Hsiang Huang, Hung-Yu Wu, & Youn-Long Lin.
                        (2021). <a href="https://github.com/james128333/HarDNet-MSEG" target="_blank">HarDNet-MSEG: A
                            Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice
                            and 86 FPS.</a></cite>
                </section>
                <section data-auto-animate>
                    <h2>Adapting a synthetic dataset</h2>
                    <img src="images/d2.png" height="300">
                    <cite style="position:fixed; bottom: 1%; left: 1%;">Taesung Park, Alexei A. Efros, Richard Zhang, &
                        Jun-Yan Zhu (2020). <a href="https://github.com/taesungp/contrastive-unpaired-translation"
                            target="_blank">Contrastive Learning for Unpaired Image-to-Image Translation.</a> <em>In
                            European Conference on Computer Vision.</em></cite>
                </section>
                <section data-auto-animate>
                    <img src="images/d2.png" height="250">
                    <pre><code class="python3" data-trim data-line-numbers="|4,5|11">
                        net_G = CutGenerator()
                        net_S = HarDMSEG()

                        adapted_image = net_G(synthetic_image)
                        prediction = net_S(adapted_image)
                        
                        loss_G = criterion_G(adapted_image, synthetic_image)
                        loss_D = criterion_D(adapted_image, synthetic_image)
                        loss_S = criterion_S(prediction, synthetic_label)

                        loss_GAN =  0.1 * (loss_G + loss_D) + 0.9 * loss_S
                        loss_GAN.backward()

                          </code></pre>

                </section>
                <section>
                    <div class="r-hstack">
                        <div style="line-height: 3em; margin-right: 1em">
                            <div>Synthetic</div>
                            <div>CycleGAN</div>
                            <div>CUT</div>
                            <div>CUT-Seg</div>
                        </div>

                        <img src="images/adapted.png" height="500">
                    </div>
                </section>

            </section>

            <section>
                <h3>Line chart with CSV data and JSON configuration</h3>
                <div style="height:480px">
                    <canvas data-chart="line">
                        My first dataset, 65, 59, 80, 81, 56, 55, 40
                        My second dataset, 28, 48, 40, 19, 86, 27, 90

                    </canvas>
                </div>
            </section>

            <!-- Pseudo-labels  -->
            <section>
                <section>
                    <h2>Pseudo-labels</h2>
                    <div class="fragment" style="text-align: left;">
                        <small>&#9744;Self-Supervised and Semi-Supervised Polyp Segmentation using Synthetic Data
                            (2023)
                        </small>
                        <small>&#9744;Fashion CUT: Unsupervised domain adaptation for visual pattern classification in
                            clothes using synthetic data and pseudo-labels (2023)</small>
                    </div>
                </section>
                <section>Diagram with PL(should I mention the tricks?)</section>
                <section>Samples fashion</section>
                <section>Code for pseudo-labels in classification</section>
                <section>Adapted images fashion</section>

            </section>

            <!-- Conclusions  -->
            <section>
                <section>
                    <h2>Conclusions</h2>
                </section>
                <section data-auto-animate>
                    <h3>Real data provides better results than synthetic data</h3>
                </section>
                <section data-auto-animate>
                    <h3>Real data provides better results than synthetic data</h3>
                    <h3>Except when less than ~100 real images are available</h3>
                </section>
                <section>
                    <h3>Synthetic data doesn't need to be realistic</h3>
                </section>
                <section>
                    <h3>Domain adaptation should be applied during training</h3>
                </section>
                <section>
                    <h3>Pseudo-labels compliment synthetic data very well</h3>
                </section>
            </section>
        </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script src="plugin/search/search.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.2.0/chart.min.js"></script>
    <script src="plugin/chart/plugin.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            controlsTutorial: false,
            progress: false,
            slideNumber: 'c',

            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealSearch, RevealZoom, RevealChart]
        });
    </script>
</body>

</html>